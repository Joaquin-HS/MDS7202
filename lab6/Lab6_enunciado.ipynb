{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Joaqu√≠n Herrera Su√°rez\n",
        "- Nombre de alumno 2: Hecmar Taucare Reyes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/Joaquin-HS/MDS7202)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 # Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset\n",
        "\n",
        "data_sets = create_data(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Funci√≥n para aplicar clustering y calcular tiempo y m√©tricas\n",
        "def clustering_analysis(X, algorithm):\n",
        "    start_time = time.time()\n",
        "    model = algorithm.fit(X)\n",
        "    labels = model.predict(X) if hasattr(model, 'predict') else model.labels_\n",
        "    silhouette_avg = silhouette_score(X, labels)\n",
        "    exec_time = time.time() - start_time\n",
        "    return labels, exec_time, silhouette_avg\n",
        "\n",
        "# Funci√≥n para crear la visualizaci√≥n usando subplots de Plotly\n",
        "def plot_scatter_subplot(fig, row, col, X, labels, exec_time, silhouette_avg, title):\n",
        "    scatter = go.Scatter(\n",
        "        x=X[:, 0], y=X[:, 1], mode='markers',\n",
        "        marker=dict(color=labels, colorscale='Viridis', size=5),\n",
        "        showlegend=False\n",
        "    )\n",
        "    # Scatter plot a la subfigura espec√≠fica\n",
        "    fig.add_trace(scatter, row=row, col=col)\n",
        "    \n",
        "    # T√≠tulo para la subfigura\n",
        "    fig.update_xaxes(title_text=f\"Tiempo: {exec_time:.2f}s | Silhouette: {silhouette_avg:.2f}\", row=row, col=col)\n",
        "    fig.update_yaxes(title_text=title, row=row, col=col)\n",
        "\n",
        "# Funci√≥n que permite ejecutar el an√°lisis con diferentes algoritmos, n_samples e hiperpar√°metros, generando subplots\n",
        "def execute_clustering_analysis(n_samples, hyperparams):\n",
        "    data_sets = create_data(n_samples)\n",
        "\n",
        "    # Se crea la figura con subplots (3 filas para datasets y 4 columnas para algoritmos)\n",
        "    fig = make_subplots(rows=3, cols=4, subplot_titles=(\"KMeans\", \"GMM\", \"Ward\", \"DBSCAN\"))\n",
        "\n",
        "    row_idx = 1\n",
        "    for dataset_name, data in data_sets.items():\n",
        "        X = data['x']\n",
        "        algo_params = hyperparams[dataset_name]  # Se obtienen los hiperpar√°metros espec√≠ficos para cada dataset\n",
        "        col_idx = 1\n",
        "        \n",
        "        # Configuraci√≥n de algoritmos con los hiperpar√°metros por dataset\n",
        "        algorithms = {\n",
        "            \"KMeans\": KMeans(n_clusters=algo_params['KMeans']['n_clusters']),\n",
        "            \"GMM\": GaussianMixture(n_components=algo_params['GMM']['n_components']),\n",
        "            \"Ward\": AgglomerativeClustering(n_clusters=algo_params['Ward']['n_clusters'], linkage='ward'),\n",
        "            \"DBSCAN\": DBSCAN(eps=algo_params['DBSCAN']['eps'])\n",
        "        }\n",
        "\n",
        "        for algo_name, algo in algorithms.items():\n",
        "            labels, exec_time, silhouette_avg = clustering_analysis(X, algo)\n",
        "            # Se llama la funci√≥n que agrega el gr√°fico en la subfigura correspondiente\n",
        "            plot_scatter_subplot(fig, row_idx, col_idx, X, labels, exec_time, silhouette_avg, f\"{dataset_name}\")\n",
        "            col_idx += 1\n",
        "        row_idx += 1\n",
        "\n",
        "    fig.update_layout(height=900, width=1200, title_text=f\"Comparaci√≥n de tiempos y desempe√±o para n_samples={n_samples}\")\n",
        "    fig.show()\n",
        "\n",
        "# Se prueba la funci√≥n con n_samples = 1000, 5000, 10000, y el siguiente diccionario de hiperpar√°metros\n",
        "hyperparams = {\n",
        "    'moons': {\n",
        "        'KMeans': {'n_clusters': 2},\n",
        "        'GMM': {'n_components': 2},\n",
        "        'Ward': {'n_clusters': 2},\n",
        "        'DBSCAN': {'eps': 0.2}\n",
        "    },\n",
        "    'blobs': {\n",
        "        'KMeans': {'n_clusters': 3},\n",
        "        'GMM': {'n_components': 3},\n",
        "        'Ward': {'n_clusters': 3},\n",
        "        'DBSCAN': {'eps': 0.3}\n",
        "    },\n",
        "    'mutated': {\n",
        "        'KMeans': {'n_clusters': 3},\n",
        "        'GMM': {'n_components': 3},\n",
        "        'Ward': {'n_clusters': 3},\n",
        "        'DBSCAN': {'eps': 0.3}\n",
        "    }\n",
        "}\n",
        "for n in [1000, 5000, 10000]:\n",
        "    execute_clustering_analysis(n, hyperparams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se ver√°n los conceptos que se deben analizar para llevar a cabo la evaluaci√≥n de las visualizaciones obtenidas:\n",
        "\n",
        "- Desempe√±o: para evaluar desempe√±o se est√° utilizando principalmente el √≠ndice de Silhouette, el cual mide cohesi√≥n y separaci√≥n entre clusters. Ahora bien, se debe destacar que esta m√©trica est√° dise√±ada principalmente para datos con formas compactas y bien separadas, algo que no ocurre en el dataset \"moons\" donde se tienen formas no convexas. Teniendo esto en mente, se puede analizar de manera visual que en el dataset \"moons\" existen dos clusters con forma de lunas entrelazadas. El algoritmo DBSCAN es el m√°s apropiado para capturar estos clusters no lineales, pero como se explic√≥ previamente, esto no se logra reflejar en la m√©trica. Ahora bien, observando el dataset \"blobs\" se tiene que, por un lado, DBSCAN no genera separaciones muy apropiadas principalmente por c√≥mo est√° dise√±ado (no optimizado para clusters bien separados en \"esferas\"), generando que muchos datos sean considerados outliers; mientras que KMeans, GMM y clustering jer√°rquico con Ward si lo logran (se refleja en el valor obtenido para el √≠ndice de Silhouette). Esto se debe a que KMeans funciona mejor con datos esfericos (en el caso de no encontrar datos esf√©ricos fuerza hasta encontrar datos con respecto al centroide en la periferia para el mejor ajuste posible); GMM funciona mejor con datos elipticos, ya que asume distribuciones normales multivariadas con un funcionamiento similar a KMeans, forzando esta vez a trav√©s de probabilidades de pertenecer a distintas gaussianas; y clustering jer√°rquico con Ward tambi√©n funciona de buena forma para datos que se ajustan a formas esf√©ricas, ya que minimiza la varianza dentro de los grupos y utiliza distancias euclidianas para capturar adecuadamente las relaciones entre los puntos. Por √∫ltimo, al observar el desempe√±o de los algoritmos en el dataset \"mutated\" se aprecia como ninguno tiene logra una segmentaci√≥n apropiada de los datos (dentro de lo esperable visualmente). En la teoria, GMM deber√≠a ser uno de los que mejor funciona debido a la forma el√≠ptica de los clusters, y eventualmente tambi√©n clustering jer√°rquico con Ward. Por su parte, DBSCAN logra una separaci√≥n y un √≠ndice de Silhouette mayor, pero como se mencion√≥, este √∫ltimo no tiene mucha relevancia para este algoritmo, adem√°s de que la segmentaci√≥n entre clusters agrupa dos de los grupos que originalmente estaban separados antes de la transformaci√≥n aplicada a \"blobs\". \n",
        "\n",
        "- Tiempos de ejecuci√≥n: en primer lugar, se destaca que a medida que aumenta `n_samples`, los tiempos de ejecuci√≥n para todos los algoritmos aumentan, lo que tiene sentido ya que en cada algoritmo se eval√∫an m√©tricas entre los puntos que se tienen, luego a mayor cantidad de puntos, mayor es el tiempo. Ahora bien, si se analizan las diferencias entre algoritmos, se exhibe que Kmeans es el m√°s eficiente en t√©rminos de tiempo de ejecuci√≥n (en general para todos los tama√±os de muestra), lo que tiene sentido ya que es el algoritmo m√°s simple dentro de los evaluados. Por su parte, GMM y DBSCAN tienen tiempos de ejecuci√≥n intermedios para los hiperpar√°metros establecidos, mientras que el clustering jer√°rquico con Ward es el m√°s lento, aumentando considerablemente (comparando con los otros algoritmos) a medida que incrementa el tama√±o de la muestra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "# 0.\n",
        "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.\n",
        "df_num = df[df.select_dtypes(include='number').columns]\n",
        "df_num.drop(columns=['id'], inplace=True)\n",
        "df_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El utilizar variables categ√≥ricas en algoritmos no supervisados sin adecuarlos previamente puede causar problemas, ya que muchos dependen de realizar c√°lculos de distancias, los cuales solo tienen sentido con valores num√©ricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Tama√±o del gr√°fico\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Se grafica la distribuci√≥n de cada variable num√©rica\n",
        "for i, col in enumerate(df_num.columns, 1):\n",
        "    plt.subplot(4, 5, i)\n",
        "    \n",
        "    if col in [\"Age\", \"Flight Distance\"]:\n",
        "        sns.histplot(df_num[col], kde=True)\n",
        "    elif col in [\"Departure Delay in Minutes\", \"Arrival Delay in Minutes\"]:\n",
        "        sns.histplot(np.log(df_num[col]+1), kde=False)\n",
        "        plt.xlabel(f'log(\"{col}\" + 1)')\n",
        "    else:\n",
        "        sns.histplot(df_num[col], kde=False)\n",
        "\n",
        "    plt.title(f'Distribuci√≥n de \"{col}\"')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An√°lisis de las distribuciones por variable:\n",
        "\n",
        "- Distribuci√≥n de \"Age\": se observa una distribuci√≥n con picos en edades entre los 20-40 a√±os y uno menor en el grupo de edad de 60-70 a√±os, lo que indica que existe una diversidad de grupos de edad entre los pasajeros.\n",
        "\n",
        "- Distribuci√≥n de \"Flight Distance\": la distribuci√≥n de los datos est√° sesgada hacia la izquierda, lo que indica que la mayor√≠a de los vuelos son de corta distancia, sin desmerecer que existen algunos vuelos de larga distancia.\n",
        "\n",
        "- Distribuci√≥n de \"Inflight wifi service\": en esta variable hay muchos pasajeros que no la calificaron (0), probablemente porque no utilizaron el servicio. Ahora bien, observando las calificaciones v√°lidas (1-5), se aprecia que existe una tendecia hacia notas bajas-intermedias (2-3).\n",
        "\n",
        "- Distribuci√≥n de \"Departure/Arrival time convenient\": las respuestas para esta variable se centran en una calificaci√≥n intermedia-alta (4), lo que sugiere que los pasajeros est√°n satisfechos pero no de manera tajante.\n",
        "\n",
        "- Distribuci√≥n de \"Ease of Online booking\": la distribuci√≥n de esta variable es pr√°cticamente id√©ntica a la que se observ√≥ en \"Inflight wifi service\".\n",
        "\n",
        "- Distribuci√≥n de \"Gate location\": las calificaciones para esta variable indican que 3 y 4 son las m√°s comunes, lo que muestra que los pasajeros tienen una satisfacci√≥n media con este servicio.\n",
        "\n",
        "- Distribuci√≥n de \"Food and drink\": esta variable genera un nivel de satisfacci√≥n muy variado entre los pasajeros, ya que los conteos est√°n muy distribuidos entre todas las calificaciones posibles.\n",
        "\n",
        "- Distribuci√≥n de \"Online boarding\": esta variable distribuye similar a \"Departure/Arrival time convenient\", con la diferencia de que las notas menores son menos notorias.\n",
        "\n",
        "- Distribuci√≥n de \"Seat comfort\": esta variable tiene un comportamiento similar a \"Online boarding\", salvo porque la mejor nota tiene una mayor preponderancia.\n",
        "\n",
        "- Distribuci√≥n de \"Inflight entertainment\": esta variable distribuye de la misma forma que \"Seat comfort\".\n",
        "\n",
        "- Distribuci√≥n de \"On-board service\": esta variable se comporta de manera equivalente a \"Online boarding\".\n",
        "\n",
        "- Distribuci√≥n de \"Leg room service\": las respuestas de esta variable se dividen en dos grupos: uno que tiene un gran nivel de satisfacci√≥n (4-5), y otro con bajo-intermedio nivel de satisfacci√≥n (2-3). N√≥tese que el primero domina sobre el segundo.\n",
        "\n",
        "- Distribuci√≥n de \"Baggage handling\": para esta variable la calificaci√≥n 4 es la m√°s com√∫n, lo que muestra que est√°n satisfechos con el manejo del equipaje, pero no en su m√°ximo nivel.\n",
        "\n",
        "- Distribuci√≥n de \"Check-in service\": las calificaciones que dominan en esta variable son la 3 y la 4, lo que sugiere un nivel de satisfacci√≥n medio-alto sobre el servicio de *check-in*.\n",
        "\n",
        "- Distribuci√≥n de \"Inflight service\": la mayor√≠a de las calificaciones son altas (4 y 5), lo que muestra satisfacci√≥n con el servicio durante el vuelo.\n",
        "\n",
        "- Distribuci√≥n de \"Cleanliness\": esta variable est√° distribuida de manera dispersa entre los pasajeros, pero con una mayor dominancia a considerar niveles de satisfacci√≥n intermedios-altos en materia de limpieza.\n",
        "\n",
        "- Distribuci√≥n de \"Departure Delay in Minutes\": la mayor√≠a de los vuelos tienen retrasos muy peque√±os (cerca de 0), pero hay una peque√±a cantidad con retrasos significativos. Existe una clara cola larga en la distribuci√≥n. N√≥tese que se incluy√≥ una transformaci√≥n logar√≠tmica para poder visualizar mejor la distribuci√≥n.\n",
        "\n",
        "- Distribuci√≥n de \"Arrival Delay in Minutes\": esta variable distribuye de la misma forma que \"Departure Delay in Minutes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3\n",
        "df_num.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es necesario escalar los datos, ya que columnas como \"Age\", \"Flight Distance\", \"Departure Delay in Minutes\" y \"Arrival Delay in Minutes\" tienen valores num√©ricos mucho m√°s grandes que las variables de satisfacci√≥n (de hecho, est√°n en otra escala), lo que implica que dominar√≠an en los algoritmos basados en distancias sobre el resto de variables. Al escalar, todas las variables tendr√°n la misma relevancia.\n",
        "\n",
        "Se utilizar√° StandardScaler, tanto para las variables num√©ricas como las categ√≥ricas ordinales, asumiendo que en estas √∫ltimas las diferencias entre niveles de satisfacci√≥n son uniformes. Se llevaron a cabo pruebas con otros escaladores (incluyendo el utilizar distintos escaladores por tipo de variable) pero ninguno entreg√≥ resultados apropiados, principalmente por esta diferencia entre los tipos de variables y c√≥mo se terminan interpretando por los modelos de machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df_num_scaled = pd.DataFrame(scaler.fit_transform(df_num), columns=df_num.columns)\n",
        "df_num_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4\n",
        "plt.figure(figsize=(12, 10))\n",
        "correlation_matrix = df_num_scaled.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlograma')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5\n",
        "df_reduced = df_num_scaled[['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']]\n",
        "df_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se seleccionaron las variables `'Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes'` debido a la baja correlaci√≥n que tienen entre s√≠ y con el resto (en general. Algunas representan grupos de variables correlacionadas linealmente), adem√°s de su intr√≠nseca importancia a la hora de evaluar la satisfacci√≥n de un pasajero de avi√≥n. Esto permite un buen balance de informaci√≥n para proceder a realizar estudios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('aerolineas_lucer.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "# 1.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Se crea el pipeline con los cambios previos (selecci√≥n de columnas y escalamiento), junto con la reducci√≥n de dimensionalidad\n",
        "columns_to_select = ['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('reduce', ColumnTransformer(\n",
        "        [('selector', 'passthrough', columns_to_select)],\n",
        "        remainder='drop')),  # Se ignoran las otras columnas\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=2))  # Reducci√≥n a dos dimensiones\n",
        "])\n",
        "\n",
        "# Se aplica el pipeline a los datos\n",
        "df_pca = pipeline.fit_transform(df)\n",
        "df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n",
        "\n",
        "df_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PC1', y='PC2', data=df_pca, alpha=0.7)\n",
        "plt.title('PCA para dos dimensiones')\n",
        "plt.xlabel('Componente principal 1')\n",
        "plt.ylabel('Componente principal 2')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El gr√°fico obtenido muestra una serie de comportamientos. En primer lugar, exhibe que existe un principal agrupamiento de datos, es decir, un cl√∫ster principal de pasajeros con caracter√≠sticas similares en t√©rminos de satisfacci√≥n. Ahora bien, tambi√©n es importante destacar que existe una cantidad no menor de outliers. Por √∫ltimo, se menciona que la variabilidad de los datos est√° representada principalmente por la primera componente principal (cierta combinaci√≥n lineal de las variables elegidas), dejando a la segunda sin tanta relevancia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('aerolineas_lucer.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Se considera que en este apartado tambi√©n hay que realizar la reducci√≥n de variables y el escalamiento.\n",
        "\n",
        "# Se crea el pipeline con los cambios previos (selecci√≥n de columnas y escalamiento), junto con el tratamiento de outliers\n",
        "columns_to_select = ['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('reduce', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('selector', 'passthrough', columns_to_select)\n",
        "        ],\n",
        "        remainder='drop')),  # Se ignoran las otras columnas\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('isolation_forest', IsolationForest(contamination=0.01, random_state=42))  # Detecta el 1% de anomal√≠as\n",
        "])\n",
        "\n",
        "# Se aplica el pipeline a los datos\n",
        "pipeline.fit(df)\n",
        "\n",
        "# Se predicen las anomal√≠as (el valor -1 indicar√° anomal√≠a y el valor 1 ser√° normal)\n",
        "anomalies = pipeline.named_steps['isolation_forest'].predict(df[columns_to_select])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se a√±aden las anomal√≠as predichas al df_pca\n",
        "df_pca['anomaly'] = anomalies\n",
        "\n",
        "# Se grafica el PCA en dos dimensiones usando las anomal√≠as como hue\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PC1', y='PC2', data=df_pca, hue='anomaly', palette={1: 'blue', -1: 'red'}, alpha=0.7)\n",
        "plt.title('PCA para dos dimensiones con detecci√≥n de anomal√≠as')\n",
        "plt.xlabel('Componente principal 1')\n",
        "plt.ylabel('Componente principal 2')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pca['anomaly'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo no est√° detectando las anomal√≠as de buena forma, ya que las distribuciones de ``Flight Distance`` y `Departure Delay in Minutes` son muy asim√©tricas, abarcando un rango amplio de valores posibles. Aplicar un filtro previo, una normalizaci√≥n menos sensible a outliers, o emplear transformaciones que reduzcan la extensi√≥n de las distribuciones podr√≠an ayudar a que el algoritmo `isolation_forest` tenga un mejor desempe√±o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('aerolineas_lucer.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Columnas relevantes\n",
        "columns_to_select = ['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']\n",
        "\n",
        "# Lista para almacenar AIC y BIC\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "\n",
        "# Diferentes n√∫meros de cl√∫sters: entre 3 y 8\n",
        "n_clusters_range = range(3, 9)\n",
        "for n_clusters in n_clusters_range:\n",
        "    # Se crea el pipeline\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('reduce', ColumnTransformer(\n",
        "            transformers=[('selector', 'passthrough', columns_to_select)],\n",
        "            remainder='drop')),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('gmm', GaussianMixture(n_components=n_clusters, random_state=42))\n",
        "    ])\n",
        "    \n",
        "    # Se ajusta el modelo a los datos\n",
        "    pipeline.fit(df)\n",
        "    \n",
        "    # Se extrae el modelo GMM\n",
        "    gmm_model = pipeline.named_steps['gmm']\n",
        "    \n",
        "    # Se calcula AIC y BIC\n",
        "    aic_scores.append(gmm_model.aic(df[columns_to_select]))\n",
        "    bic_scores.append(gmm_model.bic(df[columns_to_select]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se grafica AIC y BIC para los diferentes n√∫meros de cl√∫sters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_clusters_range, aic_scores, label='AIC', marker='o', linestyle='-', color='blue', alpha=0.7)\n",
        "plt.plot(n_clusters_range, bic_scores, label='BIC', marker='x', linestyle='--', color='red', alpha=0.7)\n",
        "plt.xlabel('N√∫mero de Cl√∫sters')\n",
        "plt.ylabel('Valor de AIC/BIC')\n",
        "plt.title('Selecci√≥n del n√∫mero √≥ptimo de cl√∫sters usando AIC y BIC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El criterio adecuado para seleccionar el n√∫mero √≥ptimo de clusters usando AIC y BIC ser√≠a minimizar ambos valores, ya que √©stos buscan encontrar modelos que logran el mejor ajuste sin agregar complejidad innecesaria. Se observa que ambas m√©tricas tienen los mismos valores para cada n√∫mero de cl√∫sters analizado, lo que tiene sentido ya que se est√°n comparando modelos sin variar el n√∫mero de datos.\n",
        "\n",
        "Con el criterio estad√≠stico mencionado, el gr√°fico expuesto indica que 5 ser√≠a el n√∫mero √≥ptimo de cl√∫sters para optimizar las campa√±as de marketing. Ahora bien, es importante destacar que las personas expertas en materia de vuelos deber√≠an realizar un estudio sobre la utilidad de esta decisi√≥n, ya que si bien es √≥ptima desde un punto de vista estad√≠stico, en t√©rminos de marketing podr√≠a ser m√°s manejable o interpretable una menor segmentaci√≥n de los pasajeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('aerolineas_lucer.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "\n",
        "# Columnas relevantes\n",
        "columns_to_select = ['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']\n",
        "\n",
        "# Se crea el pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('reduce', ColumnTransformer(\n",
        "        transformers=[('selector', 'passthrough', columns_to_select)],\n",
        "        remainder='drop')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('gmm', GaussianMixture(n_components=5, random_state=42))\n",
        "])\n",
        "    \n",
        "# Se ajusta el modelo a los datos\n",
        "pipeline.fit(df)\n",
        "\n",
        "# Se predicen los cl√∫sters\n",
        "clusters = pipeline.predict(df)\n",
        "\n",
        "# Se a√±aden los cl√∫sters al df_pca\n",
        "df_pca['cluster'] = clusters\n",
        "\n",
        "# Se grafica el PCA en dos dimensiones usando los cl√∫sters como hue\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='cluster', palette='viridis', data=df_pca, alpha=0.7)\n",
        "plt.title('Proyecci√≥n PCA de los cl√∫sters')\n",
        "plt.xlabel('Componente principal 1')\n",
        "plt.ylabel('Componente principal 2')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al observar la proyecci√≥n PCA en dos dimensiones de los cl√∫sters se aprecia que no est√°n bien separados, marcando superposiciones significativas. De esta manera, no es posible distinguir claramente entre los cl√∫sters generados. Es posible que agregando una dimensi√≥n extra se puedan distinguir de mejor forma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3\n",
        "\n",
        "# Se agrega la columna de cl√∫ster al DataFrame original\n",
        "df['Cluster'] = clusters\n",
        "\n",
        "# Se calculan estad√≠sticas descriptivas para cada cl√∫ster\n",
        "cluster_summary = df.groupby('Cluster')[columns_to_select].agg(['mean', 'std'])\n",
        "cluster_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci√≥n se presenta una descripci√≥n breve para cada cl√∫ster:\n",
        "\n",
        "- Cl√∫ster 0: este cl√∫ster cuenta con tanto un promedio como una desviaci√≥n est√°ndar alta en materia de distancias de vuelo, lo que sugiere una amplia variabilidad en este atributo. Por su parte, el servicio wifi en vuelo es de calidad media, sin mucha media ni mucha desviaci√≥n est√°ndar. Esto √∫ltimo ocurre de la misma forma para la comodidad de los asientos, mientras que se tiene un buen desempe√±o en cuanto a la puntualidad, ya que no cuenta con retrasos en las salidas.\n",
        "\n",
        "- Cl√∫ster 1: este cl√∫ster cuenta con pasajeros que tienden a volar distancias m√°s cortas en promedio (sin mucha variabilidad), con satisfacci√≥n similar con respecto al cl√∫ster anterior con respecto a la calidad del servicio wifi en vuelo y la comodidad de los asientos, pero con retrasos moderados en cuanto a la salida de los vuelos, algo a destacar a√∫n m√°s cuando los vuelos son menores en distancia.\n",
        "\n",
        "- Cl√∫ster 2: este cl√∫ster se compone de pasajeros que realizan vuelos m√°s largos en promedio que los del primer cl√∫ster, pero con la misma variabilidad. La satisfacci√≥n en cuanto al wifi es similar a los casos anteriores, pero se destaca que cuentan con un mayor confort si se analiza la comodidad de los asientos (destacando adem√°s una menor variabilidad en cuanto a la calificaci√≥n que tiene este apartado con respecto al resto de cl√∫sters). Por √∫ltimo, cuenta con un buen desempe√±o en cuanto a puntualidad (levemente peor que el cl√∫ster 0, pero mucho mejor que el cl√∫ster 1).\n",
        "\n",
        "- Cl√∫ster 3: este cl√∫ster cuenta con pasajeros que tienden a realizar vuelos de corta/media distancia (nuevamente sin mucha variabilidad). En cuanto a los atributos de satisfacci√≥n, se destaca que para tanto el wifi en vuelo como para la comodidad de los asientos, este cl√∫ster cuenta con las peores calificaciones en promedio, adem√°s de no presentar muchas variabilidad dentro de los datos que lo componen. Por √∫ltimo, viendo el retraso en la salida de los vuelos, este cl√∫ster muestra una leve tendencia a tener retrasos.\n",
        "\n",
        "- Cl√∫ster 4: este cl√∫ster se compone de los pasajeros que tienden a volar distancias m√°s largas, pero con la mayor variabilidad. Los niveles de satisfacci√≥n de wifi y comodidad de los asientos son similares a los cl√∫sters 0 y 1, y con el peor nivel de puntualidad si se compara al resto de cl√∫sters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "\n",
        "# Se crea el pipeline con los cambios previos (selecci√≥n de columnas y escalamiento), junto con la reducci√≥n de dimensionalidad\n",
        "columns_to_select = ['Flight Distance', 'Inflight wifi service', 'Seat comfort', 'Departure Delay in Minutes']\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('reduce', ColumnTransformer(\n",
        "        [('selector', 'passthrough', columns_to_select)],\n",
        "        remainder='drop')),  # Se ignoran las otras columnas\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=3))  # Reducci√≥n a tres dimensiones\n",
        "])\n",
        "\n",
        "# Se aplica el pipeline a los datos\n",
        "df_pca_3 = pipeline.fit_transform(df)\n",
        "df_pca_3 = pd.DataFrame(df_pca_3, columns=['PC1', 'PC2', 'PC3'])\n",
        "\n",
        "# Se a√±aden los cl√∫sters al df_pca\n",
        "df_pca_3['cluster'] = clusters\n",
        "\n",
        "\n",
        "\n",
        "# Se definen colores espec√≠ficos para cada cl√∫ster\n",
        "colors = ['red', 'blue', 'green', 'purple', 'orange']  # Ajusta estos colores a tu preferencia\n",
        "cluster_colors = [colors[i] for i in df_pca_3['cluster']]\n",
        "\n",
        "# Se grafica el PCA en tres dimensiones usando colores espec√≠ficos\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(df_pca_3['PC1'], df_pca_3['PC2'], df_pca_3['PC3'], c=cluster_colors, alpha=0.7)\n",
        "\n",
        "# Se crea una leyenda personalizada\n",
        "import matplotlib.patches as mpatches\n",
        "legend_handles = [mpatches.Patch(color=colors[i], label=f'Cl√∫ster {i}') for i in range(len(colors))]\n",
        "ax.legend(handles=legend_handles, title='Cl√∫sters')\n",
        "\n",
        "ax.set_title('Proyecci√≥n 3D de los Cl√∫sters')\n",
        "ax.set_xlabel('Componente principal 1')\n",
        "ax.set_ylabel('Componente principal 2')\n",
        "ax.set_zlabel('Componente principal 3')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se grafica el PCA en tres dimensiones usando colores espec√≠ficos\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(df_pca_3['PC1'], df_pca_3['PC2'], df_pca_3['PC3'], c=cluster_colors, alpha=0.7, s=1)  # s es el tama√±o de los puntos\n",
        "\n",
        "# Se crea una leyenda personalizada\n",
        "import matplotlib.patches as mpatches\n",
        "legend_handles = [mpatches.Patch(color=colors[i], label=f'Cl√∫ster {i}') for i in range(len(colors))]\n",
        "ax.legend(handles=legend_handles, title='Cl√∫sters')\n",
        "\n",
        "ax.set_title('Proyecci√≥n 3D de los Cl√∫sters')\n",
        "ax.set_xlabel('Componente principal 1')\n",
        "ax.set_ylabel('Componente principal 2')\n",
        "ax.set_zlabel('Componente principal 3')\n",
        "ax.view_init(elev=10, azim=2)  # elevaci√≥n y azimut en grados\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En primer lugar, el a√±adir una nueva componente al realizar PCA permiti√≥ que la separaci√≥n entre cl√∫sters sea levemente mejor, pero a√∫n as√≠ sin lograr evidenciar una clara segmentaci√≥n. Por otro lado, si se analizara la posibilidad de reducir el n√∫mero de cl√∫sters, se puede decir que en general todos tienen caracter√≠sticas distintivas sobre el resto (v√©ase el an√°lisis descriptivo que se llev√≥ a cabo previamente), con la posibilidad de que eventualmente se pueden juntar los cl√∫sters 0 y 2 por comportamiento relativamente similares (esto se observa en los gr√°ficos 3D tambi√©n).\n",
        "\n",
        "Por √∫ltimo, con respecto a un posible an√°lisis que se puede hacer para segmentos de pasajeros de la aerol√≠nea, se tiene que aquellos que pertenecen al cl√∫ster 3 son *low cost*, ya que en general se ven enfrentados a peores condiciones de wifi o comodidad de asientos (se asume que el pago estar√≠a relacionado a una mejor calidad de asiento/posici√≥n, luego se corresponde con su nivel de satisfacci√≥n). Por otro lado, los pasajeros del cl√∫ster 1 y 4 son similares en cuanto a su nivel de satisfacci√≥n en los atributos vistos anteriormente, presentan altos tiempos de retraso en la salida de sus vuelos, pero se diferencian de gran manera en la distancia que vuelan. Finalmente, los pasajeros del cl√∫ster 0 y 2 son muy parecidos (como se mencion√≥ previamente), destacando la mejor calificaci√≥n para comodidad de asientos en el cl√∫ster 2, y la perfecta puntualidad que experimentan los pasajeros del cl√∫ster 0."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
